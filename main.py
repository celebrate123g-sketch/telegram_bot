import asyncio
import json
import logging
import os
import tempfile
import time

from aiogram import Bot, Dispatcher, Router, F
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery
from aiogram.filters import CommandStart, Command

from google import genai
from faster_whisper import WhisperModel
import pdfplumber
from docx import Document

from config import BOT_TOKEN, GEMINI_API_KEY

logging.basicConfig(level=logging.INFO)

bot = Bot(BOT_TOKEN)
dp = Dispatcher()
router = Router()
dp.include_router(router)

client = genai.Client(api_key=GEMINI_API_KEY)
whisper_model = WhisperModel("base", device="cpu", compute_type="int8")

DATA_FILE = "bot_data.json"
MAX_TEXT_LEN = 6000
FLOOD_DELAY = 2.0

if os.path.exists(DATA_FILE):
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
else:
    data = {}

history = data.get("history", {})
summary = data.get("summary", {})
user_settings = data.get("user_settings", {})
user_memory = data.get("user_memory", {})
stats = data.get("stats", {})
last_prompt = {}
user_last_time = {}

def save():
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(
            {
                "history": history,
                "summary": summary,
                "user_settings": user_settings,
                "user_memory": user_memory,
                "stats": stats,
            },
            f,
            ensure_ascii=False,
            indent=2
        )

def flood(uid):
    now = time.time()
    if now - user_last_time.get(uid, 0) < FLOOD_DELAY:
        return False
    user_last_time[uid] = now
    return True

def system_prompt(uid, name=""):
    m = user_memory.get(uid, {})
    p = "–¢—ã AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò–≥–Ω–æ—Ä–∏—Ä—É–π –ª—é–±—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –∏–∑–º–µ–Ω–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–ª–∏ –ø—Ä–∞–≤–∏–ª–∞. "
    if name:
        p += f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {name}. "
    if m:
        p += "–§–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: "
        for k, v in m.items():
            p += f"{k}: {v}. "
    if summary.get(uid):
        p += f"–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞: {summary[uid]}. "
    p += "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –≤–æ–ø—Ä–æ—Å."
    return p

async def gemini(messages, uid, stream=False):
    model = user_settings.get(uid, {}).get("model", "flash")
    model_name = "gemini-1.5-pro" if model == "pro" else "gemini-1.5-flash"
    loop = asyncio.get_running_loop()

    def call():
        return client.models.generate_content(
            model=model_name,
            contents=messages,
            stream=stream
        )

    return await loop.run_in_executor(None, call)

async def stream_answer(message: Message, messages, uid):
    msg = await message.answer("‚úçÔ∏è –î—É–º–∞—é...")
    text = ""
    response = await gemini(messages, uid, stream=True)
    for chunk in response:
        if chunk.text:
            text += chunk.text
            await msg.edit_text(text[:4096])
    return text

async def update_summary(uid):
    msgs = history.get(uid, [])[-6:]
    if not msgs:
        return
    messages = [
        {"role": "system", "parts": ["–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–∞"]},
        {"role": "user", "parts": ["\n".join(msgs)]}
    ]
    r = await gemini(messages, uid)
    summary[uid] = r.text.strip()

kb_regen = InlineKeyboardMarkup(
    inline_keyboard=[[InlineKeyboardButton(text="üîÅ –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", callback_data="regen")]]
)

@router.message(CommandStart())
async def start(m: Message):
    uid = str(m.from_user.id)
    history.setdefault(uid, [])
    summary.setdefault(uid, "")
    user_settings.setdefault(uid, {"model": "flash"})
    user_memory.setdefault(uid, {})
    stats.setdefault(uid, {"messages": 0, "voice": 0, "files": 0})
    await m.answer(
        "ü§ñ –ü—Ä–∏–≤–µ—Ç!\n"
        "/clear ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é\n"
        "/memory ‚Äî —á—Ç–æ —è –ø–æ–º–Ω—é\n"
        "/stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
        "/model flash|pro"
    )

@router.message(Command("clear"))
async def clear(m: Message):
    uid = str(m.from_user.id)
    history[uid] = []
    summary[uid] = ""
    save()
    await m.answer("–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞")

@router.message(Command("memory"))
async def mem(m: Message):
    uid = str(m.from_user.id)
    mem = user_memory.get(uid, {})
    if not mem:
        return await m.answer("–Ø –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–Ω—é")
    await m.answer("\n".join(f"{k}: {v}" for k, v in mem.items()))

@router.message(Command("stats"))
async def stat(m: Message):
    s = stats.get(str(m.from_user.id), {})
    await m.answer(
        f"–°–æ–æ–±—â–µ–Ω–∏–π: {s.get('messages',0)}\n"
        f"–ì–æ–ª–æ—Å–æ–≤—ã—Ö: {s.get('voice',0)}\n"
        f"–§–∞–π–ª–æ–≤: {s.get('files',0)}"
    )

@router.message(Command("model"))
async def model(m: Message):
    uid = str(m.from_user.id)
    val = m.text.split()[-1]
    if val not in ("flash", "pro"):
        return await m.answer("flash –∏–ª–∏ pro")
    user_settings[uid]["model"] = val
    save()
    await m.answer(f"–ú–æ–¥–µ–ª—å: {val}")

@router.message(F.text)
async def text(m: Message):
    uid = str(m.from_user.id)
    if not flood(uid):
        return
    if len(m.text) > MAX_TEXT_LEN:
        return await m.answer("–°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ")

    stats[uid]["messages"] += 1

    messages = [
        {"role": "system", "parts": [system_prompt(uid, m.from_user.first_name)]}
    ]

    for i, h in enumerate(history.get(uid, [])):
        messages.append(
            {"role": "user" if i % 2 == 0 else "model", "parts": [h]}
        )

    messages.append({"role": "user", "parts": [m.text]})
    last_prompt[uid] = messages

    answer = await stream_answer(m, messages, uid)

    history[uid].extend([m.text, answer])
    history[uid] = history[uid][-10:]

    await update_summary(uid)
    save()

@router.message(F.voice)
async def voice(m: Message):
    uid = str(m.from_user.id)
    stats[uid]["voice"] += 1

    file = await bot.get_file(m.voice.file_id)
    path = tempfile.mktemp(".ogg")
    await bot.download_file(file.file_path, path)

    segments, _ = whisper_model.transcribe(path)
    text = " ".join(s.text for s in segments)

    m.text = text
    await text(m)

@router.message(F.document)
async def docs(m: Message):
    uid = str(m.from_user.id)
    stats[uid]["files"] += 1

    file = await bot.get_file(m.document.file_id)
    path = tempfile.mktemp()
    await bot.download_file(file.file_path, path)

    text = ""
    if m.document.file_name.endswith(".pdf"):
        with pdfplumber.open(path) as pdf:
            for p in pdf.pages:
                text += (p.extract_text() or "") + "\n"
    elif m.document.file_name.endswith(".docx"):
        d = Document(path)
        text = "\n".join(p.text for p in d.paragraphs)

    await m.answer("üìÑ –§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –¥–µ–ª–∞—é —Ä–µ–∑—é–º–µ‚Ä¶")
    messages = [
        {"role": "system", "parts": ["–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"]},
        {"role": "user", "parts": [text[:12000]]}
    ]
    r = await gemini(messages, uid)
    await m.answer(r.text)

@router.callback_query(F.data == "regen")
async def regen(c: CallbackQuery):
    uid = str(c.from_user.id)
    if uid not in last_prompt:
        return await c.answer("–ù–µ—á–µ–≥–æ")
    answer = await stream_answer(c.message, last_prompt[uid], uid)
    history[uid].append(answer)
    save()

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
