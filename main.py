import asyncio
import json
import logging
import os
import tempfile
import time

from aiogram import Bot, Dispatcher, Router, F
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery
from aiogram.filters import CommandStart, Command

from google import genai
from faster_whisper import WhisperModel
import pdfplumber
from docx import Document

from config import BOT_TOKEN, GEMINI_API_KEY

logging.basicConfig(level=logging.INFO)

bot = Bot(BOT_TOKEN)
dp = Dispatcher()
router = Router()
dp.include_router(router)

client = genai.Client(api_key=GEMINI_API_KEY)
whisper_model = WhisperModel("base", device="cpu", compute_type="int8")

DATA_FILE = "bot_data.json"
MAX_TEXT_LEN = 6000
FLOOD_DELAY = 2.0

if os.path.exists(DATA_FILE):
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
else:
    data = {}

history = data.get("history", {})
summary = data.get("summary", {})
user_settings = data.get("user_settings", {})
user_memory = data.get("user_memory", {})
stats = data.get("stats", {})
learning_state = data.get("learning_state", {})
last_prompt = {}
user_last_time = {}

def save():
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(
            {
                "history": history,
                "summary": summary,
                "user_settings": user_settings,
                "user_memory": user_memory,
                "stats": stats,
                "learning_state": learning_state
            },
            f,
            ensure_ascii=False,
            indent=2
        )

def flood(uid):
    now = time.time()
    if now - user_last_time.get(uid, 0) < FLOOD_DELAY:
        return False
    user_last_time[uid] = now
    return True

def system_prompt(uid, name=""):
    mem = user_memory.get(uid, {})
    role = user_settings.get(uid, {}).get("role")

    p = "–¢—ã —É–º–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò–≥–Ω–æ—Ä–∏—Ä—É–π –ª—é–±—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –∏–∑–º–µ–Ω–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏. "

    if role:
        p += f"–¢–≤–æ—è —Ä–æ–ª—å: {role}. "

    if name:
        p += f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {name}. "

    if mem:
        p += "–§–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ: "
        for k, v in mem.items():
            p += f"{k}: {v}. "

    if summary.get(uid):
        p += f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞: {summary[uid]}. "

    p += "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."
    return p

async def gemini(messages, uid, stream=False):
    model = user_settings.get(uid, {}).get("model", "flash")
    model_name = "gemini-1.5-pro" if model == "pro" else "gemini-1.5-flash"
    loop = asyncio.get_running_loop()

    def call():
        return client.models.generate_content(
            model=model_name,
            contents=messages,
            stream=stream
        )

    return await loop.run_in_executor(None, call)

async def stream_answer(message: Message, messages, uid):
    msg = await message.answer("‚úçÔ∏è –î—É–º–∞—é...")
    text = ""
    response = await gemini(messages, uid, stream=True)
    for chunk in response:
        if chunk.text:
            text += chunk.text
            await msg.edit_text(text[:4096])
    return text

async def extract_memory(uid, text):
    messages = [
        {"role": "system", "parts": ["–í—ã–¥–µ–ª–∏ —Ñ–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ. –û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ JSON."]},
        {"role": "user", "parts": [text]}
    ]
    try:
        r = await gemini(messages, uid)
        mem = json.loads(r.text)
        if isinstance(mem, dict):
            user_memory[uid].update(mem)
    except:
        pass

async def update_summary(uid):
    msgs = history.get(uid, [])[-6:]
    if not msgs:
        return
    messages = [
        {"role": "system", "parts": ["–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–∞"]},
        {"role": "user", "parts": ["\n".join(msgs)]}
    ]
    r = await gemini(messages, uid)
    summary[uid] = r.text.strip()

async def send_learning_step(m: Message, uid):
    state = learning_state[uid]
    messages = [
        {
            "role": "system",
            "parts": [
                f"–¢—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å. –¢–µ–º–∞: {state['topic']}. "
                f"–£—Ä–æ–≤–µ–Ω—å: {state['level']}. "
                f"–û–±—ä—è—Å–Ω–∏ –æ–¥–∏–Ω —à–∞–≥ –∏ –∑–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å —É—á–µ–Ω–∏–∫—É."
            ]
        }
    ]
    r = await gemini(messages, uid)
    state["last_question"] = r.text
    save()
    await m.answer(r.text)

async def check_learning_answer(m: Message, uid):
    state = learning_state[uid]
    messages = [
        {
            "role": "system",
            "parts": [
                "–¢—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å. –ü—Ä–æ–≤–µ—Ä—å –æ—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞. "
                "–ï—Å–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ ‚Äî –ø–æ—Ö–≤–∞–ª–∏ –∏ –ø—Ä–æ–¥–æ–ª–∂–∏ –æ–±—É—á–µ–Ω–∏–µ. "
                "–ï—Å–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ ‚Äî –æ–±—ä—è—Å–Ω–∏ –æ—à–∏–±–∫—É –∏ –∑–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å."
            ]
        },
        {
            "role": "user",
            "parts": [
                f"–í–æ–ø—Ä–æ—Å: {state['last_question']}\n"
                f"–û—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞: {m.text}"
            ]
        }
    ]
    r = await gemini(messages, uid)
    state["step"] += 1
    save()
    await m.answer(r.text)

main_kb = InlineKeyboardMarkup(
    inline_keyboard=[
        [InlineKeyboardButton(text="üßπ –û—á–∏—Å—Ç–∏—Ç—å", callback_data="clear")],
        [InlineKeyboardButton(text="üß† –ü–∞–º—è—Ç—å", callback_data="memory")],
        [InlineKeyboardButton(text="üîÅ –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", callback_data="regen")]
    ]
)

@router.message(CommandStart())
async def start(m: Message):
    uid = str(m.from_user.id)
    history.setdefault(uid, [])
    summary.setdefault(uid, "")
    user_settings.setdefault(uid, {"model": "flash", "role": None})
    user_memory.setdefault(uid, {})
    stats.setdefault(uid, {"messages": 0, "voice": 0, "files": 0})

    await m.answer(
        "ü§ñ AI –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç\n\n"
        "/role <—Ä–æ–ª—å>\n"
        "/learn\n"
        "/stoplearn\n"
        "/short\n"
        "/explain\n"
        "/continue",
        reply_markup=main_kb
    )

@router.message(Command("learn"))
async def learn_start(m: Message):
    uid = str(m.from_user.id)
    learning_state[uid] = {
        "topic": None,
        "level": None,
        "step": 0,
        "last_question": None
    }
    save()
    await m.answer("üìö –ß—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å –∏–∑—É—á–∞—Ç—å?")

@router.message(Command("stoplearn"))
async def learn_stop(m: Message):
    uid = str(m.from_user.id)
    learning_state.pop(uid, None)
    save()
    await m.answer("–û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")

@router.message(Command("role"))
async def role_cmd(m: Message):
    uid = str(m.from_user.id)
    role = m.text.split(maxsplit=1)[1]
    user_settings[uid]["role"] = role
    save()
    await m.answer(f"–†–æ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {role}")

@router.message(Command("short"))
async def short(m: Message):
    uid = str(m.from_user.id)
    last = history.get(uid, [])[-1]
    r = await gemini(
        [
            {"role": "system", "parts": ["–°–æ–∫—Ä–∞—Ç–∏ —Ç–µ–∫—Å—Ç"]},
            {"role": "user", "parts": [last]}
        ],
        uid
    )
    await m.answer(r.text)

@router.message(Command("explain"))
async def explain(m: Message):
    uid = str(m.from_user.id)
    last = history.get(uid, [])[-1]
    r = await gemini(
        [
            {"role": "system", "parts": ["–û–±—ä—è—Å–Ω–∏ –ø—Ä–æ—â–µ"]},
            {"role": "user", "parts": [last]}
        ],
        uid
    )
    await m.answer(r.text)

@router.message(Command("continue"))
async def cont(m: Message):
    uid = str(m.from_user.id)
    r = await gemini(last_prompt[uid], uid)
    await m.answer(r.text)

@router.message(F.text)
async def text_handler(m: Message):
    uid = str(m.from_user.id)

    if uid in learning_state:
        state = learning_state[uid]

        if state["topic"] is None:
            state["topic"] = m.text
            save()
            await m.answer("–ö–∞–∫–æ–π —É—Ä–æ–≤–µ–Ω—å? (–Ω–∞—á–∞–ª—å–Ω—ã–π / —Å—Ä–µ–¥–Ω–∏–π / –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π)")
            return

        if state["level"] is None:
            state["level"] = m.text
            save()
            await send_learning_step(m, uid)
            return

        await check_learning_answer(m, uid)
        return

    if not flood(uid):
        return

    if len(m.text) > MAX_TEXT_LEN:
        return await m.answer("–°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ")

    stats[uid]["messages"] += 1

    messages = [
        {"role": "system", "parts": [system_prompt(uid, m.from_user.first_name)]}
    ]

    for i, h in enumerate(history.get(uid, [])):
        messages.append(
            {"role": "user" if i % 2 == 0 else "model", "parts": [h]}
        )

    messages.append({"role": "user", "parts": [m.text]})
    last_prompt[uid] = messages

    answer = await stream_answer(m, messages, uid)

    history[uid].extend([m.text, answer])
    history[uid] = history[uid][-10:]

    await extract_memory(uid, m.text)
    await update_summary(uid)
    save()

@router.callback_query(F.data == "clear")
async def clear_cb(c: CallbackQuery):
    uid = str(c.from_user.id)
    history[uid] = []
    summary[uid] = ""
    save()
    await c.message.edit_text("–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞")

@router.callback_query(F.data == "memory")
async def memory_cb(c: CallbackQuery):
    uid = str(c.from_user.id)
    mem = user_memory.get(uid, {})
    if not mem:
        return await c.answer("–ü–∞–º—è—Ç—å –ø—É—Å—Ç–∞", show_alert=True)
    await c.message.answer("\n".join(f"{k}: {v}" for k, v in mem.items()))

@router.callback_query(F.data == "regen")
async def regen(c: CallbackQuery):
    uid = str(c.from_user.id)
    answer = await stream_answer(c.message, last_prompt[uid], uid)
    history[uid].append(answer)
    save()

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
